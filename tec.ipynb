{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "\n",
    "import mujoco as mj\n",
    "import mujoco.viewer\n",
    "import mujoco.renderer # Additional import\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "from utility import unit\n",
    "from controller import Controller\n",
    "from human import Human\n",
    "\n",
    "from sensors import Sensors\n",
    "from video_recorder import Recorder\n",
    "\n",
    "def move_simple(name, *, t, func, axis=-1, model):\n",
    "  model.site(name).pos[axis] = func(t)\n",
    "\n",
    "m = mj.MjModel.from_xml_path('./mjcf/tec.xml')\n",
    "d = mj.MjData(m)\n",
    "t = 0\n",
    "\n",
    "# Create a renderer for data collection\n",
    "r_rgb = mujoco.renderer.Renderer(m, 480, 640)\n",
    "r_depth = mujoco.renderer.Renderer(m, 480, 640)\n",
    "r_seg = mujoco.renderer.Renderer(m, 480, 640)\n",
    "r_depth.enable_depth_rendering()\n",
    "r_seg.enable_segmentation_rendering()\n",
    "\n",
    "# Create a recorder for data collection\n",
    "sensor = Sensors()\n",
    "recorder = Recorder(duration=30, \n",
    "                    fps=30, \n",
    "                    n_cameras=m.cam_user.shape[0], \n",
    "                    folder=\"./\")\n",
    "\n",
    "mujoco.mj_step(m, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mujoco.viewer.launch_passive(m, d) as viewer:\n",
    "# Close the viewer automatically after 30 wall-seconds.\n",
    "\n",
    "    start = time.time()\n",
    "    while viewer.is_running() and time.time() - start < recorder.duration:\n",
    "        step_start = time.time()\n",
    "\n",
    "        # policy\n",
    "        # mj_step can be replaced with code that also evaluates\n",
    "        # a policy and applies a contro l signal before stepping the physics.\n",
    "\n",
    "        move_simple('human1', t=t, func=lambda x: (np.sin(x)+1)/2 * 0.2 + 0.05, axis=-1, model=m)\n",
    "        move_simple('human2', t=t, func=lambda x: (np.sin(x*2)+1)/2 * 0.2 + 0.05, axis=-1, model=m)\n",
    "        move_simple('human3', t=t, func=lambda x: (np.sin(x*3)+1)/2 * 0.2 + 0.05, axis=-1, model=m)\n",
    "        mujoco.mj_step(m, d)\n",
    "        t += 0.1\n",
    "\n",
    "        # Get RGB, depth, and segmentation images\n",
    "        readings = sensor.get_rgbd_seg_matrices(m, d, r_rgb, r_depth, r_seg)\n",
    "        # Save images to recorder\n",
    "        recorder.add_frame(readings)\n",
    "\n",
    "        # Pick up changes to the physics state, apply perturbations, update options from GUI.\n",
    "        viewer.sync()\n",
    "\n",
    "        # Rudimentary time keeping, will drift relative to wall clock.\n",
    "        time_until_next_step = m.opt.timestep - (time.time() - step_start)\n",
    "        if time_until_next_step > 0:\n",
    "            time.sleep(time_until_next_step)\n",
    "            time.sleep(0.01)\n",
    "\n",
    "# Save videos\n",
    "# recorder.show_videos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Cloud Retrieve\n",
    "Code fragment of how to retrieve the point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data from the cameras\n",
    "readings = sensor.get_rgbd_seg_matrices(m, d, r_rgb, r_depth, r_seg)\n",
    "frames = [readings[i][:, :, 3] for i in range(len(readings))]\n",
    "segments = [readings[i][:, :, 4] for i in range(len(readings))]\n",
    "\n",
    "# This can be obtained from the model at the beginning of the simulation\n",
    "# Or thery can be retrieved at any time during the simulation\n",
    "# Get the position and rotation of the cameras\n",
    "poses = []\n",
    "rotations = []\n",
    "for i in range(m.cam_user.shape[0]):\n",
    "    # Get the position of the camera\n",
    "    pos = m.cam_pos[i] + m.body(m.cam_bodyid[i]).pos\n",
    "    poses.append(pos)\n",
    "\n",
    "    # Get the rotation of the camera\n",
    "    angle = R.from_quat(m.body(m.cam_bodyid[i]).quat).as_euler('xyz', degrees=True)\n",
    "    rotations.append(angle[0])\n",
    "\n",
    "\n",
    "\n",
    "# Generate point cloud from depth image\n",
    "import point_cloud as pcu\n",
    "\n",
    "point_cloud = pcu.PointCloud((480, 640), 60, downsample=2)\n",
    "\n",
    "mat = point_cloud.get_map(frames, poses, rotations)\n",
    "\n",
    "segemented_mat = point_cloud.get_segmented_map(frames, segments, poses, rotations, m)\n",
    "\n",
    "feature_vectors = point_cloud.get_feature_vectors(segmented_map=segemented_mat)\n",
    "\n",
    "# Save point cloud\n",
    "# np.save(\"point_cloud.npy\", mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 0\n",
    "for key in segemented_mat:\n",
    "    size += len(segemented_mat[key])\n",
    "\n",
    "print(\"Total -> \", mat.shape)\n",
    "print(\"Segmented -> \", size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create a 3D figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# Define the x, y, z coordinates of the point cloud\n",
    "x = mat[:, 0]\n",
    "y = mat[:, 1]\n",
    "z = mat[:, 2]\n",
    "\n",
    "# Plot the point cloud data\n",
    "ax.scatter(x, y, z, s=1)\n",
    "\n",
    "# Set the axis labels\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "for key in segemented_mat.keys():\n",
    "    mat = np.array(segemented_mat[key])\n",
    "    print(mat.shape)\n",
    "\n",
    "    # Create a 3D figure\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    fig.suptitle(key)\n",
    "\n",
    "    # Define the x, y, z coordinates of the point cloud\n",
    "    x = mat[:, 0]\n",
    "    y = mat[:, 1]\n",
    "    z = mat[:, 2]\n",
    "\n",
    "    # Plot the point cloud data\n",
    "    ax.scatter(x, y, z, s=1)\n",
    "\n",
    "    # Set the axis labels\n",
    "    ax.set_xlabel('X Label')\n",
    "    ax.set_ylabel('Y Label')\n",
    "    ax.set_zlabel('Z Label')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Reading from the dataset csv\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "dataset.head()\n",
    "\n",
    "\n",
    "# Creating the dataset class\n",
    "class MyDataset(Data):\n",
    "    def __init__(self, x, edge_index, y):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.x = x\n",
    "        self.edge_index = edge_index\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "#  Creating data for the dataset\n",
    "V = np.array(dataset.iloc[:, 2:], dtype='float32')\n",
    "\n",
    "labels = np.array(dataset.iloc[:, 1])\n",
    "for i in range(len(labels)):\n",
    "    if \"human\" in labels[i]:\n",
    "        labels[i] = 1\n",
    "    elif \"robot\" in labels[i]:\n",
    "        labels[i] = 0\n",
    "\n",
    "labels = np.array(labels, dtype='int8')\n",
    "def get_edge_index(V):\n",
    "    edges = [[],[]]\n",
    "\n",
    "    for i in range(V.shape[0]):\n",
    "        for j in range(V.shape[0]):\n",
    "            if i != j:\n",
    "                edges[0].append(i)\n",
    "                edges[1].append(j)\n",
    "\n",
    "    return np.array(edges)\n",
    "\n",
    "edges = get_edge_index(V)\n",
    "\n",
    "#  Creating the dataset as a PyTorch Geometric dataset\n",
    "data = Data(x=torch.from_numpy(V), \n",
    "            edge_index=torch.from_numpy(edges), \n",
    "            y=torch.from_numpy(labels)\n",
    "            )\n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
